{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import make_scorer\n",
    "from collections import defaultdict\n",
    "from scipy.stats import rankdata\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "def get_data(data, relevant_params):\n",
    "    task_ids = data[\"task_id\"].unique()\n",
    "    data = data[relevant_params + [\"task_id\"] + [\"predictive_accuracy\"]]\n",
    "    data_dict = defaultdict()\n",
    "    for task_id in task_ids:\n",
    "        X_task = data.loc[data[\"task_id\"] == task_id]\n",
    "        y_task = np.array(X_task[\"predictive_accuracy\"], dtype=np.float)\n",
    "        X_task.drop([\"predictive_accuracy\", \"task_id\"], 1, inplace=True)\n",
    "        categorical_names = X_task.select_dtypes(include=['object']).columns\n",
    "        categorical_ids = [X_task.columns.get_loc(colname) for colname in categorical_names]\n",
    "        data_dict[task_id] = (X_task.as_matrix(), y_task, categorical_ids)\n",
    "    return data_dict\n",
    "\n",
    "def precatn(task_id, model, X, y, kfolds=5, topn=5):\n",
    "    kf = KFold(n_splits=kfolds, random_state=42, shuffle=True)\n",
    "    splits = kf.split(X)\n",
    "    scores = []\n",
    "    for train_idx, test_idx in splits:\n",
    "        train_x, train_y = X[train_idx], y[train_idx]\n",
    "        test_x, test_y = X[test_idx], y[test_idx]\n",
    "        new_model = clone(model)\n",
    "        new_model.fit(train_x, train_y)\n",
    "        y_hat = new_model.predict(test_x)\n",
    "        y_hat_ranks = rankdata(y_hat, method=\"average\")\n",
    "        test_y_ranks = rankdata(test_y, method=\"average\")\n",
    "        y_hat_maxargs = y_hat_ranks.argsort()\n",
    "        test_y_maxargs = test_y_ranks.argsort()\n",
    "        cnt = 0\n",
    "        for entry in y_hat_maxargs[:topn]:\n",
    "            if entry in test_y_maxargs[:topn]:\n",
    "                cnt += 1\n",
    "        scores.append(cnt / topn)\n",
    "    mean_score = np.mean(scores)\n",
    "    print(\"Task %d; Precision at %d Score: %0.4f\" %(task_id, topn, mean_score))\n",
    "    return mean_score\n",
    "\n",
    "def custom_scorer(y, y_hat):\n",
    "    return pearsonr(y, y_hat)[0]\n",
    "\n",
    "def pearsonscore(task_id, model, X, y, kfolds=5):\n",
    "    # y_hat = cross_val_predict(clf, X, y, cv=kfolds)\n",
    "    # score = pearsonr(y, y_hat)[0]\n",
    "    scores = cross_val_score(model, X, y, cv=kfolds, scoring=make_scorer(custom_scorer))\n",
    "    score = scores.mean()\n",
    "    print(\"Task %d; Pearson Spearman Correlation: %0.4f (+/- %0.4f)\" %(task_id, score, scores.std() * 2))\n",
    "    return score\n",
    "\n",
    "def get_noise(task_id, model, X, y, kfolds=5):\n",
    "    kf = KFold(n_splits=kfolds, random_state=42, shuffle=True)\n",
    "    splits = kf.split(X)\n",
    "    y_hat_all = []\n",
    "    for train_idx, test_idx in splits:\n",
    "        train_x, train_y = X[train_idx], y[train_idx]\n",
    "        test_x, test_y = X[test_idx], y[test_idx]\n",
    "        new_model = clone(model)\n",
    "        new_model.fit(train_x, train_y)\n",
    "        y_hat = new_model.predict(test_x)\n",
    "        y_hat_all.append(y_hat)\n",
    "    scores = []\n",
    "    for y_hat, i in enumerate(y_hat_all):\n",
    "        for j in range(i + 1, topn):\n",
    "            scores.append(pearsonr(y_hat, y_hat_all[j]))\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prernakashyap/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3694: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "/Users/prernakashyap/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "filename = \"./data/results__2000__svc__predictive_accuracy.arff\"\n",
    "relevant_params = [\"svc__C\", \"svc__gamma\"]\n",
    "data, meta = arff.loadarff(filename)\n",
    "df = pd.DataFrame(data)\n",
    "data_dict = get_data(df, relevant_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class surrogate:\n",
    "\n",
    "    def __init__(self, ntrees=16):\n",
    "        self.models = {}\n",
    "        self.ntrees = ntrees\n",
    "\n",
    "    def train_model_rs(self, X, y, categoricals, task_id):\n",
    "        if task_id in self.models:\n",
    "            return self.models[task_id]\n",
    "        param_dist = {\"max_depth\": np.arange(3, 11),\n",
    "              \"max_features\": [1, 2],\n",
    "              \"n_estimators\" : [100],\n",
    "              \"min_samples_split\": np.arange(2, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"mse\", \"mae\"]}\n",
    "        clf = Pipeline(\n",
    "            steps=[('encoder', sklearn.preprocessing.OneHotEncoder(\n",
    "                categorical_features=list(categoricals), handle_unknown='ignore')),\n",
    "                    ('random search', RandomizedSearchCV(RandomForestRegressor(n_estimators=self.ntrees), \n",
    "                                                         param_distributions=param_dist,\n",
    "                                                         n_iter=200, cv=5))])\n",
    "        clf.fit(X, y)\n",
    "        self.models[task_id] = clf\n",
    "        return clf\n",
    "    \n",
    "    def train_model(self, X, y, categoricals, task_id):\n",
    "        if task_id in self.models:\n",
    "            return self.models[task_id]\n",
    "        clf = Pipeline(\n",
    "            steps=[('encoder', sklearn.preprocessing.OneHotEncoder(\n",
    "                categorical_features=list(categoricals), handle_unknown='ignore')),\n",
    "                    ('classifier', RandomForestRegressor(n_estimators=self.ntrees))])\n",
    "        clf.fit(X, y)\n",
    "        self.models[task_id] = clf\n",
    "        return clf\n",
    "\n",
    "    def train_surrogate(self, data_dict):\n",
    "        task_ids = list(data_dict.keys())\n",
    "        scores = []\n",
    "        for task_id in task_ids:\n",
    "            X, y, categoricals = data_dict[task_id]\n",
    "            clf = self.train_model_rs(X, y, categoricals, task_id)\n",
    "            precatn_score = precatn(task_id, clf.named_steps[\"random search\"].best_estimator_, X, y, topn=200)\n",
    "            pearson_score = pearsonscore(task_id, clf.named_steps[\"random search\"].best_estimator_, X, y)\n",
    "            scores.append(np.array([precatn_score, pearson_score]))\n",
    "        return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = surrogate()\n",
    "surrogate_scores = s.train_surrogate(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/prernakashyap/Documents/autoML research/models/sm2.pkl', 'wb') as f:\n",
    "    pickle.dump(s.models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prernakashyap/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator OneHotEncoder from version 0.19.0 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/prernakashyap/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 0.19.0 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/prernakashyap/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator RandomForestRegressor from version 0.19.0 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/prernakashyap/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator RandomizedSearchCV from version 0.19.0 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/prernakashyap/anaconda3/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.0 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "surrogate_models = pickle.load(open('/Users/prernakashyap/Documents/autoML research/models/sm2.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 3; Precision at 200 Score: 0.6970\n",
      "Task 3; Pearson Spearman Correlation: 0.5827 (+/- 0.1114)\n",
      "Task 6; Precision at 200 Score: 0.6780\n",
      "Task 6; Pearson Spearman Correlation: 0.5414 (+/- 0.0603)\n",
      "Task 11; Precision at 200 Score: 0.6700\n",
      "Task 11; Pearson Spearman Correlation: 0.2356 (+/- 0.0918)\n",
      "Task 12; Precision at 200 Score: 0.6650\n",
      "Task 12; Pearson Spearman Correlation: 0.5041 (+/- 0.0707)\n",
      "Task 14; Precision at 200 Score: 0.7490\n",
      "Task 14; Pearson Spearman Correlation: 0.5548 (+/- 0.1549)\n",
      "Task 15; Precision at 200 Score: 0.6240\n",
      "Task 15; Pearson Spearman Correlation: 0.4640 (+/- 0.1984)\n",
      "Task 16; Precision at 200 Score: 0.7110\n",
      "Task 16; Pearson Spearman Correlation: 0.4850 (+/- 0.1246)\n",
      "Task 18; Precision at 200 Score: 0.7210\n",
      "Task 18; Pearson Spearman Correlation: 0.3022 (+/- 0.0780)\n",
      "Task 20; Precision at 200 Score: 0.6920\n",
      "Task 20; Pearson Spearman Correlation: 0.5741 (+/- 0.0516)\n",
      "Task 21; Precision at 200 Score: 0.7960\n",
      "Task 21; Pearson Spearman Correlation: 0.5570 (+/- 0.0671)\n",
      "Task 22; Precision at 200 Score: 0.7090\n",
      "Task 22; Pearson Spearman Correlation: 0.5993 (+/- 0.1323)\n",
      "Task 23; Precision at 200 Score: 0.7110\n",
      "Task 23; Pearson Spearman Correlation: 0.3456 (+/- 0.0520)\n",
      "Task 24; Precision at 200 Score: 0.6700\n",
      "Task 24; Pearson Spearman Correlation: 0.4678 (+/- 0.1351)\n",
      "Task 28; Precision at 200 Score: 0.6950\n",
      "Task 28; Pearson Spearman Correlation: 0.5659 (+/- 0.1280)\n",
      "Task 29; Precision at 200 Score: 0.7730\n",
      "Task 29; Pearson Spearman Correlation: 0.5707 (+/- 0.0472)\n",
      "Task 31; Precision at 200 Score: 0.6040\n",
      "Task 31; Pearson Spearman Correlation: 0.2591 (+/- 0.0598)\n",
      "Task 32; Precision at 200 Score: 0.6500\n",
      "Task 32; Pearson Spearman Correlation: 0.4332 (+/- 0.0973)\n",
      "Task 36; Precision at 200 Score: 0.6380\n",
      "Task 36; Pearson Spearman Correlation: 0.2737 (+/- 0.1113)\n",
      "Task 37; Precision at 200 Score: 0.7660\n",
      "Task 37; Pearson Spearman Correlation: 0.3690 (+/- 0.0702)\n",
      "Task 41; Precision at 200 Score: 0.8080\n",
      "Task 41; Pearson Spearman Correlation: 0.6990 (+/- 0.0502)\n",
      "Task 43; Precision at 200 Score: 0.7460\n",
      "Task 43; Pearson Spearman Correlation: 0.4223 (+/- 0.0880)\n",
      "Task 45; Precision at 200 Score: 0.7560\n",
      "Task 45; Pearson Spearman Correlation: 0.5934 (+/- 0.0575)\n",
      "Task 49; Precision at 200 Score: 0.7940\n",
      "Task 49; Pearson Spearman Correlation: 0.5694 (+/- 0.0689)\n",
      "Task 53; Precision at 200 Score: 0.7180\n",
      "Task 53; Pearson Spearman Correlation: 0.5458 (+/- 0.0278)\n",
      "Task 58; Precision at 200 Score: 0.7360\n",
      "Task 58; Pearson Spearman Correlation: 0.4365 (+/- 0.0949)\n",
      "Task 219; Precision at 200 Score: 0.5930\n",
      "Task 219; Pearson Spearman Correlation: 0.2907 (+/- 0.1024)\n",
      "Task 2074; Precision at 200 Score: 0.6400\n",
      "Task 2074; Pearson Spearman Correlation: 0.4374 (+/- 0.0881)\n",
      "Task 2079; Precision at 200 Score: 0.7720\n",
      "Task 2079; Pearson Spearman Correlation: 0.5734 (+/- 0.0573)\n",
      "Task 3021; Precision at 200 Score: 0.7010\n",
      "Task 3021; Pearson Spearman Correlation: 0.2590 (+/- 0.0441)\n",
      "Task 3022; Precision at 200 Score: 0.7190\n",
      "Task 3022; Pearson Spearman Correlation: 0.3899 (+/- 0.0922)\n",
      "Task 3481; Precision at 200 Score: 0.6790\n",
      "Task 3481; Pearson Spearman Correlation: 0.5081 (+/- 0.1438)\n",
      "Task 3485; Precision at 200 Score: 0.6610\n",
      "Task 3485; Pearson Spearman Correlation: 0.4118 (+/- 0.0443)\n",
      "Task 3492; Precision at 200 Score: 0.6520\n",
      "Task 3492; Pearson Spearman Correlation: 0.3836 (+/- 0.0969)\n",
      "Task 3493; Precision at 200 Score: 0.6170\n",
      "Task 3493; Pearson Spearman Correlation: 0.3366 (+/- 0.0767)\n",
      "Task 3494; Precision at 200 Score: 0.7250\n",
      "Task 3494; Pearson Spearman Correlation: 0.7317 (+/- 0.0621)\n",
      "Task 3510; Precision at 200 Score: 0.6920\n",
      "Task 3510; Pearson Spearman Correlation: 0.6070 (+/- 0.0881)\n",
      "Task 3512; Precision at 200 Score: 0.7280\n",
      "Task 3512; Pearson Spearman Correlation: 0.4729 (+/- 0.0966)\n",
      "Task 3543; Precision at 200 Score: 0.7570\n",
      "Task 3543; Pearson Spearman Correlation: 0.5941 (+/- 0.0708)\n",
      "Task 3549; Precision at 200 Score: 0.8140\n",
      "Task 3549; Pearson Spearman Correlation: 0.4936 (+/- 0.0363)\n",
      "Task 3560; Precision at 200 Score: 0.6690\n",
      "Task 3560; Pearson Spearman Correlation: 0.3659 (+/- 0.0788)\n",
      "Task 3561; Precision at 200 Score: 0.5450\n",
      "Task 3561; Pearson Spearman Correlation: 0.3209 (+/- 0.1008)\n",
      "Task 3567; Precision at 200 Score: 0.8010\n",
      "Task 3567; Pearson Spearman Correlation: 0.7337 (+/- 0.0683)\n"
     ]
    }
   ],
   "source": [
    "surrogate_scores = []\n",
    "task_ids = list(data_dict.keys())\n",
    "for task_id in task_ids:\n",
    "    X, y, categoricals = data_dict[task_id]\n",
    "    clf = surrogate_models.models[task_id].named_steps[\"random search\"].best_estimator_\n",
    "    precatn_score = precatn(task_id, clf, X, y, topn=200)\n",
    "    pearson_score = pearsonscore(task_id, clf, X, y)\n",
    "    surrogate_scores.append(np.array([precatn_score, pearson_score]))\n",
    "surrogate_scores = np.array(surrogate_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = alpha * hyperparameter_1 ^ 2 + beta * hyperparameter_2 ^ 2 + gamma * hyperparameter_1 * hyperparameter_2 + delta\n",
    "# hyperparameter_1 = gamma\n",
    "# hyperparameter_2 = complexity (C)\n",
    "class simplified_surrogate:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "\n",
    "    def train_model(self, data_dict):\n",
    "        scores = []\n",
    "        for task_id in data_dict:\n",
    "            X, y, _ = data_dict[task_id]\n",
    "            poly = PolynomialFeatures(2)\n",
    "            X = poly.fit_transform(X)\n",
    "            X = np.delete(X, 1, 1)\n",
    "            X = np.delete(X, 2, 1)\n",
    "            model = LinearRegression()\n",
    "            model.fit(X, y)\n",
    "            self.models[task_id] = model\n",
    "            precatn_score = precatn(task_id, model, X, y, topn=200)\n",
    "            pearson_score = pearsonscore(task_id, model, X, y)\n",
    "            scores.append(np.array([precatn_score, pearson_score]))\n",
    "        return np.array(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 3; Precision at 200 Score: 0.4470\n",
      "Task 3; Pearson Spearman Correlation: 0.2470 (+/- 0.1423)\n",
      "Task 6; Precision at 200 Score: 0.4950\n",
      "Task 6; Pearson Spearman Correlation: 0.1489 (+/- 0.0988)\n",
      "Task 11; Precision at 200 Score: 0.4390\n",
      "Task 11; Pearson Spearman Correlation: 0.0665 (+/- 0.0601)\n",
      "Task 12; Precision at 200 Score: 0.6470\n",
      "Task 12; Pearson Spearman Correlation: 0.3519 (+/- 0.1232)\n",
      "Task 14; Precision at 200 Score: 0.6800\n",
      "Task 14; Pearson Spearman Correlation: 0.4443 (+/- 0.1841)\n",
      "Task 15; Precision at 200 Score: 0.3900\n",
      "Task 15; Pearson Spearman Correlation: 0.0818 (+/- 0.0577)\n",
      "Task 16; Precision at 200 Score: 0.6680\n",
      "Task 16; Pearson Spearman Correlation: 0.3616 (+/- 0.1153)\n",
      "Task 18; Precision at 200 Score: 0.4980\n",
      "Task 18; Pearson Spearman Correlation: 0.1940 (+/- 0.0785)\n",
      "Task 20; Precision at 200 Score: 0.6530\n",
      "Task 20; Pearson Spearman Correlation: 0.3400 (+/- 0.1157)\n",
      "Task 21; Precision at 200 Score: 0.4540\n",
      "Task 21; Pearson Spearman Correlation: 0.0630 (+/- 0.0998)\n",
      "Task 22; Precision at 200 Score: 0.6270\n",
      "Task 22; Pearson Spearman Correlation: 0.5499 (+/- 0.1054)\n",
      "Task 23; Precision at 200 Score: 0.4990\n",
      "Task 23; Pearson Spearman Correlation: 0.2203 (+/- 0.0264)\n",
      "Task 24; Precision at 200 Score: 0.4500\n",
      "Task 24; Pearson Spearman Correlation: 0.2931 (+/- 0.0962)\n",
      "Task 28; Precision at 200 Score: 0.5980\n",
      "Task 28; Pearson Spearman Correlation: 0.3783 (+/- 0.0929)\n",
      "Task 29; Precision at 200 Score: 0.6160\n",
      "Task 29; Pearson Spearman Correlation: 0.2460 (+/- 0.0265)\n",
      "Task 31; Precision at 200 Score: 0.4750\n",
      "Task 31; Pearson Spearman Correlation: 0.2103 (+/- 0.0449)\n",
      "Task 32; Precision at 200 Score: 0.5030\n",
      "Task 32; Pearson Spearman Correlation: 0.1600 (+/- 0.0644)\n",
      "Task 36; Precision at 200 Score: 0.4970\n",
      "Task 36; Pearson Spearman Correlation: 0.1365 (+/- 0.1042)\n",
      "Task 37; Precision at 200 Score: 0.5710\n",
      "Task 37; Pearson Spearman Correlation: 0.2162 (+/- 0.0676)\n",
      "Task 41; Precision at 200 Score: 0.4920\n",
      "Task 41; Pearson Spearman Correlation: 0.2396 (+/- 0.0680)\n",
      "Task 43; Precision at 200 Score: 0.6390\n",
      "Task 43; Pearson Spearman Correlation: 0.0899 (+/- 0.0752)\n",
      "Task 45; Precision at 200 Score: 0.6470\n",
      "Task 45; Pearson Spearman Correlation: 0.2602 (+/- 0.0867)\n",
      "Task 49; Precision at 200 Score: 0.4530\n",
      "Task 49; Pearson Spearman Correlation: 0.1268 (+/- 0.0545)\n",
      "Task 53; Precision at 200 Score: 0.5430\n",
      "Task 53; Pearson Spearman Correlation: 0.1788 (+/- 0.0568)\n",
      "Task 58; Precision at 200 Score: 0.6590\n",
      "Task 58; Pearson Spearman Correlation: 0.2728 (+/- 0.1293)\n",
      "Task 219; Precision at 200 Score: 0.5020\n",
      "Task 219; Pearson Spearman Correlation: 0.1354 (+/- 0.0961)\n",
      "Task 2074; Precision at 200 Score: 0.5610\n",
      "Task 2074; Pearson Spearman Correlation: 0.2379 (+/- 0.0705)\n",
      "Task 2079; Precision at 200 Score: 0.5400\n",
      "Task 2079; Pearson Spearman Correlation: 0.2229 (+/- 0.0357)\n",
      "Task 3021; Precision at 200 Score: 0.4320\n",
      "Task 3021; Pearson Spearman Correlation: 0.0860 (+/- 0.0679)\n",
      "Task 3022; Precision at 200 Score: 0.6150\n",
      "Task 3022; Pearson Spearman Correlation: 0.0344 (+/- 0.1179)\n",
      "Task 3481; Precision at 200 Score: 0.6850\n",
      "Task 3481; Pearson Spearman Correlation: 0.2245 (+/- 0.0768)\n",
      "Task 3485; Precision at 200 Score: 0.6140\n",
      "Task 3485; Pearson Spearman Correlation: 0.1183 (+/- 0.0734)\n",
      "Task 3492; Precision at 200 Score: 0.5860\n",
      "Task 3492; Pearson Spearman Correlation: 0.0839 (+/- 0.0525)\n",
      "Task 3493; Precision at 200 Score: 0.5850\n",
      "Task 3493; Pearson Spearman Correlation: 0.1990 (+/- 0.1045)\n",
      "Task 3494; Precision at 200 Score: 0.6140\n",
      "Task 3494; Pearson Spearman Correlation: 0.1075 (+/- 0.0858)\n",
      "Task 3510; Precision at 200 Score: 0.5200\n",
      "Task 3510; Pearson Spearman Correlation: 0.2595 (+/- 0.1171)\n",
      "Task 3512; Precision at 200 Score: 0.6370\n",
      "Task 3512; Pearson Spearman Correlation: 0.3864 (+/- 0.1004)\n",
      "Task 3543; Precision at 200 Score: 0.5030\n",
      "Task 3543; Pearson Spearman Correlation: 0.0710 (+/- 0.0403)\n",
      "Task 3549; Precision at 200 Score: 0.7020\n",
      "Task 3549; Pearson Spearman Correlation: 0.1621 (+/- 0.0855)\n",
      "Task 3560; Precision at 200 Score: 0.4120\n",
      "Task 3560; Pearson Spearman Correlation: 0.2107 (+/- 0.1148)\n",
      "Task 3561; Precision at 200 Score: 0.5030\n",
      "Task 3561; Pearson Spearman Correlation: 0.1771 (+/- 0.1354)\n",
      "Task 3567; Precision at 200 Score: 0.5130\n",
      "Task 3567; Pearson Spearman Correlation: 0.1966 (+/- 0.0786)\n"
     ]
    }
   ],
   "source": [
    "s_ = simplified_surrogate()\n",
    "simplified_surrogate_scores = s_.train_model(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_plot(data, offset,edge_color, fill_color):\n",
    "    pos = np.arange(1) + offset \n",
    "    bp = ax.boxplot(data, positions= pos, widths=0.3, patch_artist=True, manage_xticks=False)\n",
    "    for element in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']:\n",
    "        plt.setp(bp[element], color=edge_color)\n",
    "    for patch in bp['boxes']:\n",
    "        patch.set(facecolor=fill_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boxplot for pearson correlation measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "draw_plot(surrogate_scores[:,0], -0.2, \"tomato\", \"white\")\n",
    "draw_plot(simplified_surrogate_scores[:,0], +0.2, \"skyblue\", \"white\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boxplot for precision at 200 measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEZlJREFUeJzt3XGMnHl93/H3BwfTNgkN4L0Wzj7stKayuSJO3TiV4oZcc6i+RrEj9ZLYFSpIvlqUGKpSVTEyOlWuLN1Rqah/uC3uGQkiYXOc1GRLnbPKxZHiKJd6yV0v8lmGxaX1yojzHRDapsHn8u0fO0fnlrH32fXMzuzP75c08vN7np+e+Wi8+uyzz8zzTKoKSVJbXjfuAJKk4bPcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ36kXE98YYNG2rz5s3jenpJWpO+/OUvv1RVU0vNG1u5b968mdnZ2XE9vSStSUn+e5d5npaRpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNWhsFzGteQ/vGneCyfD4U+NOIGkAy32lJqHUHt41GTkkTRxPy0hSgyx3SWqQ5S5JDbLcJalBnco9ya4kl5LMJTk0YPsnkzzXe3wlyXeGH1WS1NWSn5ZJsg44BrwXmAfOJ5mpqhdenVNV/6Rv/oeB+0aQVZLUUZcj9x3AXFVdrqrrwClgzy3m7wNODiOcJGllupT73cCVvvF8b90PSfJ2YAvwO7cfTZK0Ul3KPQPW1U3m7gWerKr/O3BHyYEks0lmr1271jWjJGmZupT7PLCpb7wRuHqTuXu5xSmZqjpeVdNVNT01teT3u0qSVqhLuZ8HtibZkmQ9CwU+s3hSkr8GvAn4g+FGlCQt15LlXlU3gIPAGeAi8ERVXUhyJMnuvqn7gFNVdbNTNpKkVdLpxmFVdRo4vWjdI4vG/3x4sSRJt8MrVCWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGdSr3JLuSXEoyl+TQTeb8SpIXklxI8rnhxpQkLceSX5CdZB1wDHgvMA+cTzJTVS/0zdkKfAz4mar6dpK7RhVYkrS0LkfuO4C5qrpcVdeBU8CeRXP+IXCsqr4NUFUvDjemJGk5upT73cCVvvF8b12/dwDvSPL7SZ5JsmtYASVJy7fkaRkgA9bVgP1sBX4O2Aj8XpJ7q+o7r9lRcgA4AHDPPfcsO6wkqZsuR+7zwKa+8Ubg6oA5v1VVr1TVfwMusVD2r1FVx6tquqqmp6amVppZkrSELuV+HtiaZEuS9cBeYGbRnN8E7gdIsoGF0zSXhxlUktTdkuVeVTeAg8AZ4CLwRFVdSHIkye7etDPAy0leAM4C/6yqXh5VaEnSrXU5505VnQZOL1r3SN9yAR/tPSRJY+YVqpLUIMtdkhpkuUtSgzqdc584v/4P4GUvggXg4Tv8erG33AWPfXbcKaSJszbL/eUX4fGnxp1Ck+BO/+Um3YSnZSSpQZa7pJE7efIk9957L+vWrePee+/l5MmT447UvLV5WkbSmnHy5EkOHz7MiRMn2LlzJ+fOnWP//v0A7Nu3b8zp2uWRu6SROnr0KCdOnOD+++/n9a9/Pffffz8nTpzg6NGj447WNMtd0khdvHiRnTt3vmbdzp07uXjx4pgS3Rksd0kjtW3bNs6dO/eadefOnWPbtm1jSnRnsNwljdThw4fZv38/Z8+e5ZVXXuHs2bPs37+fw4cPjzta03xDVdJIvfqm6Yc//GEuXrzItm3bOHr0qG+mjpjlLmnk9u3bZ5mvMk/LSFKDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZ1Kvcku5JcSjKX5NCA7R9Ici3Jc73Hw8OPKknqasnPuSdZBxwD3gvMA+eTzFTVC4umfr6qDo4goyRpmbocue8A5qrqclVdB04Be0YbS5J0O7qU+93Alb7xfG/dYn8vyfNJnkyyadCOkhxIMptk9tq1ayuIK0nqoku5Z8C6WjT+j8DmqnoX8CXgM4N2VFXHq2q6qqanpqaWl1SS1FmXcp8H+o/ENwJX+ydU1ctV9b3e8N8Df2M48SRJK9Gl3M8DW5NsSbIe2AvM9E9I8ta+4W7Au/BL0hgt+WmZqrqR5CBwBlgHfLqqLiQ5AsxW1QzwkSS7gRvAt4APjDCzJGkJnW75W1WngdOL1j3St/wx4GPDjSZJWqm1ez/3h3eNO4EkTay1W+6PPzXuBJoE/pKXBvLeMpLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGrd2LmCQt26PPvjTuCBPh0H0bxh1h5Cx36Q4y7lJ79NmXxp7hTuFpGUlqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGtSp3JPsSnIpyVySQ7eY91CSSjI9vIiSpOVastyTrAOOAQ8C24F9SbYPmPfjwEeAPxx2SEnS8nQ5ct8BzFXV5aq6DpwC9gyY9y+ATwB/NsR8kqQV6FLudwNX+sbzvXU/kOQ+YFNVfXGI2SRJK9Sl3DNgXf1gY/I64JPAP11yR8mBJLNJZq9du9Y9pSRpWbqU+zywqW+8EbjaN/5x4F7gd5N8HfibwMygN1Wr6nhVTVfV9NTU1MpTS5JuqUu5nwe2JtmSZD2wF5h5dWNV/UlVbaiqzVW1GXgG2F1VsyNJLEla0pLlXlU3gIPAGeAi8ERVXUhyJMnuUQeUJC1fp/u5V9Vp4PSidY/cZO7P3X4sSdLt8ApVSWqQ5S5JDVqbX7P3lrvg4V3jTqFJ8Ja7xp1Amkhrs9wf++y4E0yGh3fB40+NO4WkCeRpGUlqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhrUqdyT7EpyKclckkMDtn8wyR8neS7JuSTbhx9VktTVkuWeZB1wDHgQ2A7sG1Den6uqv15V7wY+AfyroSeVJHXW5ch9BzBXVZer6jpwCtjTP6Gqvts3/FGghhdRkrRcXb5m727gSt94HvjpxZOS/BrwUWA98LeHkk6StCJdjtwzYN0PHZlX1bGq+ivArwMfH7ij5ECS2SSz165dW15SSVJnXcp9HtjUN94IXL3F/FPALw3aUFXHq2q6qqanpqa6p5QkLUuXcj8PbE2yJcl6YC8w0z8hyda+4S8AXx1eREnSci15zr2qbiQ5CJwB1gGfrqoLSY4As1U1AxxM8gDwCvBt4P2jDC1JurUub6hSVaeB04vWPdK3/I+HnEuSdBu8QlWSGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZ1+py7pNv3by58i+9e//64Y4zdo8++NO4IY/fG9a/jQ+9880ifw3KXVsl3r3+fQ/dtGHcMTYDV+AXnaRlJapDlLkkNstwlqUGWuyQ1yDdUV+rhXeNOsGDcOR5/arzPL2kgy32lLDVJE8zTMpLUIMtdkhpkuUtSgyx3SWpQp3JPsivJpSRzSQ4N2P7RJC8keT7J00nePvyokqSuliz3JOuAY8CDwHZgX5Lti6Y9C0xX1buAJ4FPDDuoJKm7LkfuO4C5qrpcVdeBU8Ce/glVdbaq/rQ3fAbYONyYkqTl6PI597uBK33jeeCnbzF/P/DbtxNKapW3u9Vq6VLuGbCuBk5M3gdMA++5yfYDwAGAe+65p2NEqR3e8lcwObf8nQc29Y03AlcXT0ryAHAY2F1V3xu0o6o6XlXTVTU9NTW1krySpA66lPt5YGuSLUnWA3uBmf4JSe4DPsVCsb84/JiSpOVYstyr6gZwEDgDXASeqKoLSY4k2d2b9i+BHwO+kOS5JDM32Z0kaRV0unFYVZ0GTi9a90jf8gNDziVJug1eoSpJDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDOt3PXdLte+P61/kF2QIWfhZGzXKXVsmH3vnmcUcYu0effckvCV8lnpaRpAZZ7pLUIMtdkhrUqdyT7EpyKclckkMDtv9skj9KciPJQ8OPKUlajiXLPck64BjwILAd2Jdk+6Jp/wP4APC5YQeUJC1fl0/L7ADmquoyQJJTwB7ghVcnVNXXe9u+P4KMkqRl6nJa5m7gSt94vrdu2ZIcSDKbZPbatWsr2YUkqYMu5Z4B62olT1ZVx6tquqqmp6amVrILSVIHXcp9HtjUN94IXB1NHEnSMHQp9/PA1iRbkqwH9gIzo40lSbodS5Z7Vd0ADgJngIvAE1V1IcmRJLsBkvxUknngl4FPJbkwytCSpFvrdG+ZqjoNnF607pG+5fMsnK6RJE0Ar1CVpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqUKe7Qkpqw6PPvjTuCBOR4dB9G8YdYeQsd+kOcieUmhZ4WkaSGmS5S1KDLHdJapDlLkkN6lTuSXYluZRkLsmhAdvfkOTzve1/mGTzsINKkrpbstyTrAOOAQ8C24F9SbYvmrYf+HZV/VXgk8Bjww4qSequy5H7DmCuqi5X1XXgFLBn0Zw9wGd6y08CP58kw4spSVqOLuV+N3ClbzzfWzdwTlXdAP4EeMswAkqSlq/LRUyDjsBrBXNIcgA40Bv+rySXOjz/atoAjP/yue7WUl6zjs5ayruWssJk5n17l0ldyn0e2NQ33ghcvcmc+SQ/AvxF4FuLd1RVx4HjXYKNQ5LZqpoed46u1lJes47OWsq7lrLC2svbr8tpmfPA1iRbkqwH9gIzi+bMAO/vLT8E/E5V/dCRuyRpdSx55F5VN5IcBM4A64BPV9WFJEeA2aqaAU4Av5FkjoUj9r2jDC1JurVONw6rqtPA6UXrHulb/jPgl4cbbSwm9pTRTaylvGYdnbWUdy1lhbWX9wfi2RNJao+3H5CkBt3R5Z7kzUn+c5Kv9v5904A5b0/y5STPJbmQ5IMTnPXdSf6gl/P5JL86jqy9LEvm7c17Ksl3knxxDBnX1G01OuT92SR/lORGkofGkbEvy1JZP5rkhd7P6dNJOn28b1Q65P1gkj/u9cC5AVfpT56qumMfwCeAQ73lQ8BjA+asB97QW/4x4OvA2yY06zuArb3ltwHfAH5iUl/b3rafB34R+OIq51sHfA34yd7/8X8Fti+a8yHg3/WW9wKfH8druYy8m4F3AZ8FHprwrPcDf6G3/I/WwGv7xr7l3cBT48rb9XFHH7nz2tsmfAb4pcUTqup6VX2vN3wD4/trp0vWr1TVV3vLV4EXgalVS/haS+YFqKqngf+5WqH6rLXbaiyZt6q+XlXPA98fR8A+XbKerao/7Q2fYeH6mXHpkve7fcMfZcBFmpPmTi/3v1RV3wDo/XvXoElJNiV5noVbLDzWK87V1inrq5LsYOEo5GurkG2QZeUdg7V2W40ueSfFcrPuB357pIlurVPeJL+W5Gss/FX6kVXKtmLNf4dqki8Bf3nApsNd91FVV4B3JXkb8JtJnqyqbw4r46uGkbW3n7cCvwG8v6pGdhQ3rLxjMrTbaqySScqylM5Zk7wPmAbeM9JEt9Ypb1UdA44l+fvAx/n/F25OpObLvaoeuNm2JN9M8taq+kavEF9cYl9Xk1wA/hYLf6YP1TCyJnkj8J+Aj1fVM8PO2G+Yr+0YDO22GqukS95J0SlrkgdYOBB4T9+pz3FY7mt7Cvi3I000BHf6aZn+2ya8H/itxROSbEzy53vLbwJ+BhjHDc+6ZF0P/Afgs1X1hVXMNsiSecdsrd1Wo0veSbFk1iT3AZ8CdlfVuH/xd8m7tW/4C8BXVzHfyoz7Hd1xPlg4f/o0C/9RTwNv7q2fBh7vLb8XeJ6Fd9CfBw5McNb3Aa8Az/U93j2peXvj3wOuAf+HhSOov7OKGf8u8BUW3pc43Ft3hIXCAfhzwBeAOeC/AD855p/XpfL+VO81/N/Ay8CFCc76JeCbfT+nMxP+2v5r4EIv61ngnePM2+XhFaqS1KA7/bSMJDXJcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUH/D32s/mprxRywAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "draw_plot(surrogate_scores[:,1], -0.2, \"tomato\", \"white\")\n",
    "draw_plot(simplified_surrogate_scores[:,1], +0.2, \"skyblue\", \"white\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- RF, decision tree, gradient boosting\n",
    "- use MSE\n",
    "- leave one out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lentask = []\n",
    "for task_id in task_ids:\n",
    "  lentask.append(data_dict[task_id])  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
